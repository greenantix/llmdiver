This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where comments have been removed, empty lines have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter).

# File Summary

## Purpose
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A header with the file path (## File: path/to/file)
  b. The full contents of the file in a code block

## Usage Guidelines
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: *.py, *.js, *.ts, *.jsx, *.tsx, *.sh
- Files matching these patterns are excluded: *.md, *.log, *.tmp, node_modules, __pycache__, .git, .llmdiver
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Files are sorted by Git change count (files with more changes are at the bottom)

# Directory Structure
```
audit.sh
claude_sync_template.sh
easy_install.sh
install.sh
llmdiver_daemon.py
llmdiver-daemon.py
run_llm_audit.sh
send_to_claude.sh
setup_env.sh
start_llmdiver.sh
start_with_audit.sh
start-llmdiver.sh
test_llmdiver.sh
watch_and_audit.sh
```

# Files

## File: audit.sh
```bash
SCRIPT_DIR="$(dirname "$0")"
PROJECT_ROOT="$SCRIPT_DIR"
LM_URL="http://localhost:1234"
TIMEOUT=600
while [[ $
    case $1 in
        --timeout)
            TIMEOUT="$2"
            shift 2
            ;;
        --lm-url)
            LM_URL="$2"
            shift 2
            ;;
        *)
            echo "Unknown option: $1"
            echo "Usage: $0 [--timeout SECONDS] [--lm-url URL]"
            exit 1
            ;;
    esac
done
echo "🔍 Checking LM Studio connection..."
curl -s "$LM_URL/v1/models" > /dev/null
if [ $? -ne 0 ]; then
    echo "❌ Error: LM Studio server is not running at $LM_URL"
    echo "Please start LM Studio and ensure a model is loaded"
    echo "Or specify a different URL with --lm-url"
    exit 1
fi
echo "Settings:"
echo "• LM Studio URL: $LM_URL"
echo "• Analysis timeout: ${TIMEOUT}s"
echo "🔍 Starting comprehensive project audit using LM Studio..."
echo "This will perform a deep analysis of the codebase using AI."
echo "The analysis may take several minutes depending on the model and codebase size."
mkdir -p "$PROJECT_ROOT/audits"
echo -e "\n📋 Running deep code analysis..."
timeout ${TIMEOUT} python3 "$PROJECT_ROOT/tools/deep_audit.py" \
    "$PROJECT_ROOT" \
    --timeout "$TIMEOUT" \
    --lm-url "$LM_URL" &
PID=$!
DOTS=0
while kill -0 $PID 2>/dev/null; do
    echo -n "."
    DOTS=$((DOTS + 1))
    if [ $DOTS -eq 50 ]; then
        echo
        DOTS=0
    fi
    sleep 1
done
wait $PID
EXIT_CODE=$?
if [ $EXIT_CODE -eq 124 ]; then
    echo -e "\n❌ Analysis timed out after ${TIMEOUT} seconds!"
    echo "Try increasing timeout with --timeout option"
    exit 1
fi
if [ $? -ne 0 ]; then
    echo -e "\n❌ Analysis failed! Check the error messages above."
    exit 1
fi
cat > "$PROJECT_ROOT/audits/executive_summary.md" << EOL
Generated on: $(date "+%Y-%m-%d %H:%M:%S")
This is an automated summary of the comprehensive project analysis. The full detailed report can be found in \`audits/deep_analysis.md\`.
$(grep -A 5 "^## Layer" "$PROJECT_ROOT/audits/deep_analysis.md" | sed 's/^/- /')
$(grep -A 3 "### Security Concerns\|### Performance Issues" "$PROJECT_ROOT/audits/deep_analysis.md" | sed 's/^/- /')
1. Review and address all security concerns identified in the full report
2. Optimize performance bottlenecks highlighted in the analysis
3. Consider implementing suggested architectural improvements
4. Update documentation based on the current codebase structure
For detailed findings and recommendations, please review the complete analysis in \`audits/deep_analysis.md\`.
EOL
echo -e "\n📑 Generating final reports..."
if [ ! -f "$PROJECT_ROOT/audits/deep_analysis.md" ]; then
    echo -e "\n❌ Analysis failed to generate reports!"
    exit 1
fi
echo -e "\n✅ Analysis complete!"
echo -e "\nReport generated: audits/deep_analysis.md"
echo -e "\nThe report includes:"
echo "• Executive Summary of findings"
echo "• Detailed analysis of project structure"
echo "• Core functionality assessment"
echo "• Code quality metrics"
echo "• Security & performance insights"
echo "• Actionable recommendations"
echo -e "\nReview the report for comprehensive findings and improvement suggestions."
```

## File: claude_sync_template.sh
```bash
set -e
REPO_DIR="$(pwd)"
PROJECT_NAME="$(basename "$REPO_DIR")"
AUDIT_DIR="./audits/$PROJECT_NAME"
mkdir -p "$AUDIT_DIR"
echo "🔍 Starting LLMdiver audit for $PROJECT_NAME"
llm-audit-quick
echo "✅ Audit complete for $PROJECT_NAME"
echo "📁 Results saved in $AUDIT_DIR"
```

## File: easy_install.sh
```bash
set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TARGET_PROJECT_DIR="$(pwd)"
TARGET_BIN_DIR="$TARGET_PROJECT_DIR/node_modules/.bin"
if ! command -v jq &> /dev/null; then
    echo "❌ Error: jq is required but not installed"
    echo "Please install jq first:"
    echo "  Ubuntu/Debian: sudo apt-get install jq"
    echo "  MacOS: brew install jq"
    exit 1
fi
mkdir -p "$TARGET_BIN_DIR"
mkdir -p "$TARGET_PROJECT_DIR/audits"
LLMDIVER_DIR="$SCRIPT_DIR"
AUDIT_MAIN="$LLMDIVER_DIR/run_llm_audit.sh"
AUDIT_QUICK="$LLMDIVER_DIR/audit.sh"
CLAUDE_SYNC="$LLMDIVER_DIR/claude_sync_template.sh"
for file in "$AUDIT_MAIN" "$AUDIT_QUICK" "$CLAUDE_SYNC"; do
    if [[ ! -f "$file" ]]; then
        echo "❌ Error: Required file not found: $file"
        exit 1
    fi
done
ln -sf "$AUDIT_MAIN" "$TARGET_BIN_DIR/llm-audit"
ln -sf "$AUDIT_QUICK" "$TARGET_BIN_DIR/llm-audit-quick"
ln -sf "$CLAUDE_SYNC" "$TARGET_BIN_DIR/claude-sync"
chmod +x "$AUDIT_MAIN" "$AUDIT_QUICK" "$CLAUDE_SYNC"
CONFIG_DIR="$TARGET_PROJECT_DIR/config"
mkdir -p "$CONFIG_DIR"
if [[ ! -f "$CONFIG_DIR/llmdiver.json" ]]; then
    cat > "$CONFIG_DIR/llmdiver.json" << EOF
{
    "llm_model": "meta-llama-3.1-8b-instruct",
    "llm_temp": 0.3,
    "llm_url": "http://127.0.0.1:1234/v1/chat/completions"
}
EOF
fi
echo "✅ LLMdiver installed successfully!"
echo "Available commands:"
echo "  - llm-audit         (full deep scan)"
echo "  - llm-audit-quick   (smart fast audit)"
echo "  - claude-sync       (full auto Claude loop)"
echo ""
echo "Configuration:"
echo "  - Config file: $CONFIG_DIR/llmdiver.json"
echo "  - Audit results will be saved in: $TARGET_PROJECT_DIR/audits"
echo ""
echo "Make sure LM Studio is running before using the audit commands!"
```

## File: install.sh
```bash
set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TARGET_DIR="$SCRIPT_DIR/node_modules/.bin"
mkdir -p "$TARGET_DIR"
AUDIT_MAIN="$SCRIPT_DIR/run_llm_audit.sh"
AUDIT_QUICK="$SCRIPT_DIR/audit.sh"
CLAUDE_SYNC="$SCRIPT_DIR/claude_sync_template.sh"
if [[ ! -f "$AUDIT_MAIN" ]]; then
    AUDIT_MAIN="$(realpath "$SCRIPT_DIR/../LLMdiver/run_llm_audit.sh")"
    AUDIT_QUICK="$(realpath "$SCRIPT_DIR/../LLMdiver/audit.sh")"
    CLAUDE_SYNC="$(realpath "$SCRIPT_DIR/../LLMdiver/claude_sync_template.sh")"
fi
# Create symlinks
ln -sf "$AUDIT_MAIN" "$TARGET_DIR/llm-audit"
ln -sf "$AUDIT_QUICK" "$TARGET_DIR/llm-audit-quick"
ln -sf "$CLAUDE_SYNC" "$TARGET_DIR/claude-sync"
chmod +x "$AUDIT_MAIN" "$AUDIT_QUICK" "$CLAUDE_SYNC"
echo "✅ LLMdiver installed into $TARGET_DIR"
echo "Available commands:"
echo "  - llm-audit         (full deep scan)"
echo "  - llm-audit-quick   (smart fast audit)"
echo "  - claude-sync       (full auto Claude loop)"
```

## File: llmdiver_daemon.py
```python
class LLMdiverConfig
⋮----
def __init__(self, config_path: str = "config/llmdiver.json")
def load_config(self) -> Dict
⋮----
default_config = {
⋮----
config = json.load(f)
⋮----
class RepoWatcher(FileSystemEventHandler)
⋮----
def __init__(self, daemon, repo_config)
def on_modified(self, event)
⋮----
file_path = Path(event.src_path)
triggers = self.repo_config["analysis_triggers"]
⋮----
current_time = time.time()
⋮----
class LLMStudioClient
⋮----
def __init__(self, config)
def chunk_text(self, text: str, chunk_size: int = 16000) -> List[str]
⋮----
words = text.split()
chunks = []
current_chunk = []
current_length = 0
⋮----
word_length = len(word) + 1
⋮----
current_chunk = [word]
current_length = word_length
⋮----
def analyze_repo_summary(self, summary_text: str) -> str
⋮----
system_prompt = """You are an expert code auditor. Analyze the repository summary and identify:
enable_chunking = self.config["llm_integration"].get("enable_chunking", False)
chunk_size = self.config["llm_integration"].get("chunk_size", 16000)
⋮----
chunks = self.chunk_text(summary_text, chunk_size)
all_analyses = []
⋮----
chunk_prompt = f"Analyze this repository section ({i+1}/{len(chunks)}):\n\n{chunk}"
analysis = self._send_single_request(system_prompt, chunk_prompt)
⋮----
combined = "\n\n".join(all_analyses)
final_prompt = f"Summarize and consolidate these code audit findings:\n\n{combined}"
⋮----
def _send_single_request(self, system_prompt: str, user_prompt: str) -> str
⋮----
payload = {
⋮----
response = requests.post(self.url, json=payload, timeout=300)
⋮----
result = response.json()
⋮----
error_text = ""
⋮----
error_data = e.response.json()
error_text = error_data.get("error", e.response.text)
⋮----
error_text = e.response.text
⋮----
class GitAutomation
⋮----
def analyze_changes(self, repo_path: str) -> Dict
⋮----
repo = git.Repo(repo_path)
modified_files = [item.a_path for item in repo.index.diff(None)]
untracked_files = repo.untracked_files
total_changes = len(modified_files) + len(untracked_files)
⋮----
def generate_commit_message(self, analysis: str, changes: Dict) -> str
⋮----
lines = analysis.split('\n')
critical_issues = []
todos = []
improvements = []
current_section = ""
⋮----
line = line.strip()
⋮----
current_section = "critical"
⋮----
current_section = "todos"
⋮----
current_section = "improvements"
⋮----
summary_parts = []
⋮----
summary = ", ".join(summary_parts) if summary_parts else "Update codebase"
details = []
⋮----
details_text = "\n".join(details)
⋮----
def auto_commit(self, repo_path: str, analysis: str) -> bool
⋮----
changes = self.analyze_changes(repo_path)
⋮----
repo = changes["repo"]
⋮----
message = self.generate_commit_message(analysis, changes)
⋮----
origin = repo.remote('origin')
⋮----
class ManifestAnalyzer
⋮----
def find_manifests(self, repo_path: str) -> List[str]
⋮----
manifests = []
repo_path = Path(repo_path)
⋮----
manifest_path = repo_path / manifest_file
⋮----
def analyze_manifest(self, manifest_path: str) -> Dict
⋮----
manifest_path = Path(manifest_path)
⋮----
content = f.read()
content_hash = hashlib.sha256(content.encode()).hexdigest()
analysis = {
⋮----
def _analyze_package_json(self, content: str) -> Dict
⋮----
data = json.loads(content)
dependencies = list(data.get("dependencies", {}).keys())
dev_dependencies = list(data.get("devDependencies", {}).keys())
⋮----
def _analyze_requirements_txt(self, content: str) -> Dict
⋮----
dependencies = []
⋮----
package = line.split('==')[0].split('>=')[0].split('<=')[0].split('~=')[0].strip()
⋮----
def _analyze_cargo_toml(self, content: str) -> Dict
⋮----
dev_dependencies = []
lines = content.split('\n')
current_section = None
⋮----
current_section = "dependencies"
⋮----
current_section = "dev_dependencies"
⋮----
package = line.split('=')[0].strip()
⋮----
def check_manifest_changes(self, repo_path: str) -> List[Dict]
⋮----
manifests = self.find_manifests(repo_path)
changes = []
⋮----
analysis = self.analyze_manifest(manifest_path)
⋮----
cache_key = manifest_path
⋮----
cached_analysis = self.manifests_cache[cache_key]
⋮----
class MultiProjectManager
⋮----
def discover_projects(self) -> List[Dict]
⋮----
projects = []
⋮----
pattern_path = item / pattern
⋮----
project_config = {
⋮----
def get_project_manifest_info(self, project_path: str) -> Dict
⋮----
manifest_analyzer = ManifestAnalyzer({"manifest_analysis": {"manifest_files": ["package.json", "requirements.txt", "Cargo.toml"]}})
manifests = manifest_analyzer.find_manifests(project_path)
info = {
⋮----
analysis = manifest_analyzer.analyze_manifest(manifest_path)
⋮----
class LLMdiverDaemon
⋮----
def setup_logging(self)
⋮----
log_level = getattr(logging, self.config.config["daemon"]["log_level"])
⋮----
def run_repomix_analysis(self, repo_path: str) -> str
⋮----
output_file = f"{repo_path}/.llmdiver_analysis.md"
cmd = [
result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
⋮----
def schedule_analysis(self, repo_config: Dict)
def process_analysis_queue(self)
⋮----
repo_config = self.analysis_queue.pop(0)
⋮----
def analyze_repository(self, repo_config: Dict)
def start_watching(self)
⋮----
repo_path = repo_config["path"]
⋮----
observer = Observer()
handler = RepoWatcher(self, repo_config)
⋮----
def start(self)
⋮----
analysis_thread = threading.Thread(target=self.process_analysis_queue)
⋮----
def discover_and_add_projects(self)
⋮----
discovered_projects = self.multi_project_manager.discover_projects()
existing_paths = {repo["path"] for repo in self.config.config["repositories"]}
⋮----
def analyze_manifest_changes(self, repo_config: Dict) -> str
⋮----
changes = self.manifest_analyzer.check_manifest_changes(repo_config["path"])
⋮----
analysis_text = "## Manifest Analysis\n\n"
⋮----
def enhanced_repository_analysis(self, repo_config: Dict)
⋮----
summary = self.run_repomix_analysis(repo_config["path"])
⋮----
manifest_analysis = self.analyze_manifest_changes(repo_config)
project_info = self.multi_project_manager.get_project_manifest_info(repo_config["path"])
enhanced_summary = f"""# Repository Analysis: {repo_config['name']}
analysis = self.llm_client.analyze_repo_summary(enhanced_summary)
analysis_dir = Path(repo_config["path"]) / ".llmdiver"
⋮----
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
analysis_file = analysis_dir / f"enhanced_analysis_{timestamp}.md"
⋮----
latest_link = analysis_dir / "latest_enhanced_analysis.md"
⋮----
commit_message = f"Enhanced analysis including manifest changes and project context"
enhanced_analysis_data = {
⋮----
def stop(self)
def signal_handler(signum, frame)
⋮----
daemon = LLMdiverDaemon()
```

## File: llmdiver-daemon.py
```python
logger = logging.getLogger('llmdiver-daemon')
class Config
⋮----
def __init__(self)
def load_config(self)
class GitAutomation
⋮----
def __init__(self, config, repo_config)
def should_commit(self, changed_files)
⋮----
current = self.repo.active_branch.name
⋮----
def generate_commit_message(self, analysis_result)
⋮----
template = self.config['commit_message_template']
summary = "Updated code analysis"
details = "Changes detected by LLMdiver automated analysis"
⋮----
summary = analysis_result['summary']
details = analysis_result.get('details', '')
⋮----
def commit_and_push(self, changed_files, analysis_result)
⋮----
message = self.generate_commit_message(analysis_result)
⋮----
def update_documentation(self)
⋮----
docs_path = Path(self.repo_config['path']) / 'docs'
⋮----
index_path = docs_path / 'llmdiver_analysis.md'
⋮----
analysis_path = Path(self.repo_config['path']) / '.llmdiver/repomix.md'
⋮----
class MetricsCollector
⋮----
def load_metrics(self)
def save_metrics(self)
def update_system_metrics(self)
⋮----
process = psutil.Process()
⋮----
def get_project_size(self) -> float
⋮----
total = 0
⋮----
def record_analysis(self, duration: float, token_count: int)
⋮----
stats = self.metrics['analysis']
⋮----
def record_api_call(self, endpoint: str, success: bool)
⋮----
stats = self.metrics['api']['requests'][endpoint]
⋮----
def record_git_operation(self, operation: str)
def get_metrics(self) -> Dict
class RepomixProcessor
⋮----
def __init__(self, config)
def run_analysis(self, repo_path)
⋮----
repomix_config = self.config['repomix']
output_dir = Path(repo_path) / '.llmdiver'
⋮----
output_file = output_dir / 'repomix.md'
cmd = [
⋮----
start_time = time.time()
⋮----
result = subprocess.run(cmd, check=True, capture_output=True, text=True)
duration = time.time() - start_time
⋮----
encoder = tiktoken.get_encoding("cl100k_base")
token_count = len(encoder.encode(result.stdout))
⋮----
token_count = len(result.stdout) // 4
⋮----
git_automation = self.git_automations[repo_config['name']]
changed_files = self.get_changed_files(repo_path)
⋮----
analysis_result = self.parse_analysis_result(output_file)
⋮----
def get_changed_files(self, repo_path)
⋮----
repo = git.Repo(repo_path)
⋮----
def parse_analysis_result(self, output_file)
⋮----
content = f.read()
lines = content.split('\n')
⋮----
class FileChangeHandler(FileSystemEventHandler)
⋮----
def __init__(self, processor)
def on_modified(self, event)
⋮----
current_time = time.time()
⋮----
repo_path = os.path.dirname(event.src_path)
⋮----
class APIHandler(BaseHTTPRequestHandler)
⋮----
def __init__(self, *args, processor=None, **kwargs)
def do_GET(self)
⋮----
repos = [{'name': r['name'], 'path': r['path']}
⋮----
parts = self.path.split('/')
⋮----
repo_name = parts[2]
action = parts[3]
repo = self.get_repo_config(repo_name)
⋮----
issues = self.get_repo_issues(repo)
⋮----
insights = self.get_repo_insights(repo)
⋮----
def do_POST(self)
⋮----
content_length = int(self.headers.get('content-length', 0))
⋮----
body = self.rfile.read(content_length)
data = json.loads(body)
⋮----
repo_path = self.clone_remote_repo(data['url'], repo_name)
⋮----
def send_json_response(self, data)
def get_repo_config(self, repo_name)
def get_repo_issues(self, repo)
⋮----
analysis_file = Path(repo['path']) / '.llmdiver/repomix.md'
⋮----
issues_section = content.split('## Issues')[1].split('##')[0]
⋮----
def get_repo_insights(self, repo)
⋮----
insights_section = content.split('## Insights')[1].split('##')[0]
⋮----
def clone_remote_repo(self, url, repo_name)
⋮----
base_path = Path(self.processor.config['repositories'][0]['path']).parent
repo_path = base_path / repo_name
⋮----
event_handler = FileChangeHandler(self.processor)
observer = Observer()
⋮----
def main()
⋮----
config = Config()
processor = RepomixProcessor(config.config)
⋮----
repo_path = repo_config['path']
event_handler = FileChangeHandler(processor)
⋮----
daemon_config = config.config['daemon']
server = HTTPServer(
```

## File: run_llm_audit.sh
```bash
set -e
if ! command -v jq &> /dev/null; then
    echo "❌ Error: jq is required but not installed"
    echo "Please install jq first:"
    echo "  Ubuntu/Debian: sudo apt-get install jq"
    echo "  MacOS: brew install jq"
    exit 1
fi
DRY_RUN=0
FAST_MODE=0
DEEP_MODE=0
SHOW_PAYLOAD=0
REPO_PATH=""
print_usage() {
    echo "Usage: $0 [OPTIONS] [path/to/repo]"
    echo
    echo "Options:"
    echo "  --dry           Dry run - only generate repo summary"
    echo "  --fast          Fast mode - minimal summary + quick LLM pass"
    echo "  --deep          Deep mode - full repo + architectural audit"
    echo "  --show-payload  Show LLM payload without running"
    echo "  -h, --help      Show this help message"
    echo
    echo "If no path is specified, the current directory will be used."
    exit 1
}
while [[ "$#" -gt 0 ]]; do
    case $1 in
        --dry) DRY_RUN=1 ;;
        --fast) FAST_MODE=1 ;;
        --deep) DEEP_MODE=1 ;;
        --show-payload) SHOW_PAYLOAD=1 ;;
        -h|--help) print_usage ;;
        --*) echo "❌ Unknown option: $1"; print_usage ;;
        *)
            if [[ -n "$REPO_PATH" ]]; then
                echo "❌ Multiple paths specified: $REPO_PATH and $1"
                print_usage
            fi
            REPO_PATH="$(realpath "$1")" ;;
    esac
    shift
done
# Fallback to current directory if no path specified
[[ -z "$REPO_PATH" ]] && REPO_PATH="$(pwd)"
if [[ ! -d "$REPO_PATH" ]]; then
    echo "❌ Error: Target directory not found: $REPO_PATH"
    echo "Usage: $0 [path/to/repo] [--dry] [--fast] [--deep]"
    exit 1
fi
PROJECT_NAME=$(basename "$REPO_PATH")
BASE_DIR="$(dirname "$REPO_PATH")"
AUDIT_DIR="$BASE_DIR/audits/$PROJECT_NAME"
TASKS_DIR="$AUDIT_DIR/tasks"
PROMPTS_DIR="$AUDIT_DIR/prompts"
LOGS_DIR="$AUDIT_DIR/logs"
TMP_DIR="$AUDIT_DIR/.tmp"
PROMPT_FILE="$PROMPTS_DIR/audit_plan.txt"
AUDIT_OUT="$AUDIT_DIR/full_audit.md"
PHASE4_LOG="$LOGS_DIR/${PROJECT_NAME}-phase4.md"
MIXED_FILE="$AUDIT_DIR/_repomix_summary.txt"
DEEP_AUDIT_FILE="$AUDIT_DIR/full_deep_audit.md"
CLAUDE_FILE="$AUDIT_DIR/claude.md"
for dir in "$AUDIT_DIR" "$TASKS_DIR" "$PROMPTS_DIR" "$LOGS_DIR" "$TMP_DIR"; do
    mkdir -p "$dir" || {
        echo "❌ Failed to create directory: $dir"
        exit 1
    }
done
rm -rf "$TMP_DIR"/*
export LLM_MODEL=${LLM_MODEL:-"meta-llama-3.1-8b-instruct"}
export LLM_TEMP=${LLM_TEMP:-0.3}
export LLM_URL=${LLM_URL:-"http://127.0.0.1:1234/v1/chat/completions"}
SUMMARY_FILE="$AUDIT_DIR/_repomix_summary.txt"
if [[ $DRY_RUN -eq 1 ]]; then
    echo "🔍 Dry run - will only generate repo summary"
elif [[ $FAST_MODE -eq 1 ]]; then
    echo "⚡ Fast mode enabled - minimal summary + fast LLM pass"
elif [[ $DEEP_MODE -eq 1 ]]; then
    echo "🧠 Deep mode enabled - full repo + architectural audit"
else
    echo "🔍 Standard audit - full summary + LLM analysis"
fi
if [[ -f "$REPO_PATH/.gitignore" ]]; then
    cp "$REPO_PATH/.gitignore" "$REPO_PATH/.gitignore.backup"
fi
cat > "$REPO_PATH/.gitignore.llmdiver" << EOF
node_modules/
dist/
build/
venv/
__pycache__/
.git/
site-packages/
*.log
*.tmp
EOF
echo "🔀 Generating repo mix with repomix..." > "$SUMMARY_FILE"
repomix "$REPO_PATH" \
  --output "$SUMMARY_FILE" \
  --style markdown \
  --compress \
  --remove-comments \
  --remove-empty-lines \
  --ignore "*.md" \
  --config-ignore ".gitignore.llmdiver" \
  --include "*.py,*.js,*.ts,*.jsx,*.tsx,*.sh" \
  --token-count-encoding cl100k_base
if [[ -f "$REPO_PATH/.gitignore.backup" ]]; then
    mv "$REPO_PATH/.gitignore.backup" "$REPO_PATH/.gitignore"
fi
echo "✅ Repomix summary created: $SUMMARY_FILE"
if [[ $DRY_RUN -eq 1 ]]; then
    exit 0
fi
if [[ $SHOW_PAYLOAD -eq 1 ]]; then
    echo "📋 Generating LM Studio payload preview..."
    generate_repomix
    user_prompt=$(cat "$MIXED_FILE" | jq -Rs .)
    system_prompt="You are a world-class code auditor. Analyze the following condensed repo summary and return issues grouped by TODOs, mocks/stubs, dead code, and unwired components."
    escaped_system_prompt=$(echo "$system_prompt" | jq -Rs .)
    echo "🔍 Payload that would be sent to LM Studio:"
    cat <<EOF | jq .
{
  "model": "$LLM_MODEL",
  "messages": [
    { "role": "system", "content": ${escaped_system_prompt} },
    { "role": "user", "content": ${user_prompt} }
  ],
  "temperature": $LLM_TEMP,
  "max_tokens": 4096,
  "stream": false
}
EOF
    exit 0
fi
function send_to_lm_studio() {
  local input_file="$1"
  local output_file="$2"
  local model="${LLM_MODEL:-meta-llama-3.1-8b-instruct}"
  local temperature="${LLM_TEMP:-0.3}"
  local lm_url="${LLM_URL:-http://127.0.0.1:1234/v1/chat/completions}"
  local system_prompt
  if [[ $DEEP_MODE -eq 1 ]]; then
    system_prompt="You are an advanced software architect AI. Your job is to perform a full architectural, functional, and structural audit of the provided code summary.
Based on the summary, identify:
- Unused or redundant files, dead code, and config bloat
- Mismatched or missing module connections
- Conflicting responsibilities or naming patterns
- Orphaned logic, test coverage gaps, inconsistent structure
- Architectural violations or breakdowns in cohesion
Your goal is to help a code-repair assistant (Claude Code) intelligently fix the project structure.
Format output as:
## High-Level Assessment
<overview>
## Actionable Structural Issues
<bulleted list>
## Suggested Refactor Plans
<sections with headings for each problem>
## Claude Code Subtask Guidance
<list of Claude prompt suggestions to delegate fixes>"
  else
    system_prompt="You are a world-class code auditor. Analyze the following condensed repo summary and return issues grouped by TODOs, mocks/stubs, dead code, and unwired components."
  fi
  local user_prompt
  user_prompt=$(cat "$input_file" | jq -Rs .)
  local escaped_system_prompt
  escaped_system_prompt=$(echo "$system_prompt" | jq -Rs .)
  echo "📤 Sending repomix summary to LM Studio..."
  local payload
  payload=$(cat <<EOF
{
  "model": "$model",
  "messages": [
    { "role": "system", "content": ${escaped_system_prompt} },
    { "role": "user", "content": ${user_prompt} }
  ],
  "temperature": $temperature,
  "max_tokens": 4096,
  "stream": false
}
EOF
)
  local timeout=30
  [[ $DEEP_MODE -eq 1 ]] && timeout=120
  if ! curl -sf "$lm_url" >/dev/null 2>&1; then
    echo "❌ Error: LM Studio API not accessible at $lm_url"
    echo "Make sure LM Studio is running and API is enabled"
    exit 1
  fi
  response=$(curl -sS --max-time $timeout "$lm_url" \
    -H "Content-Type: application/json" \
    -d "$payload")
  if [[ $? -ne 0 ]]; then
    echo "❌ Error: Failed to connect to LM Studio"
    echo "Check if the service is running and accessible"
    exit 1
  fi
  if ! echo "$response" | jq -e '.choices[0].message.content' >/dev/null 2>&1; then
    echo "❌ Error: Invalid response from LM Studio"
    echo "Raw response: $response"
    exit 1
  fi
  echo "$response" | jq -r '.choices[0].message.content' > "$output_file"
  if [[ -s "$output_file" ]]; then
    if [[ $DEEP_MODE -eq 1 ]]; then
      echo "✅ Deep architectural audit complete: $output_file"
      echo "📄 To view the report, run: less $output_file"
    else
      echo "✅ LM Studio responded. Output saved to: $output_file"
    fi
  else
    echo "❌ LM Studio returned empty response. Check the summary or model settings."
  fi
}
echo "🔎 Extracting codebase signals..."
generate_repomix() {
    if [[ ! -f "$REPO_PATH/.gitignore.llmdiver" ]]; then
        cat > "$REPO_PATH/.gitignore.llmdiver" << EOF
node_modules/
dist/
build/
venv/
__pycache__/
.git/
site-packages/
*.log
*.tmp
EOF
    fi
    echo "🔀 Generating repo mix with repomix..." > "$MIXED_FILE"
    repomix "$REPO_PATH" \
        --output "$MIXED_FILE" \
        --style markdown \
        --compress \
        --remove-comments \
        --remove-empty-lines \
        --ignore "*.md" \
        --config-ignore ".gitignore.llmdiver" \
        --include "*.py,*.js,*.ts,*.jsx,*.tsx,*.sh" \
        --token-count-encoding cl100k_base
    local line_count=$(wc -l < "$MIXED_FILE")
    echo -e "\n✅ Repomix summary created ($line_count lines)\n" >> "$MIXED_FILE"
    if [[ $FAST_MODE -eq 1 ]]; then
        less "$MIXED_FILE"
    fi
}
generate_repomix
if [[ ! -f "$PROMPT_FILE" ]]; then
    echo "ℹ️ No audit plan found, using default..."
    mkdir -p "$PROMPTS_DIR" || {
        echo "❌ Failed to create prompts directory: $PROMPTS_DIR"
        exit 1
    }
    cat > "$PROMPT_FILE" << 'EOF'
You are an expert software auditor analyzing a codebase.
Focus on:
1. TODOs and tech debt that need addressing
2. Dead or duplicate code that can be removed
3. Mock/stub implementations that should be replaced
4. Unwired or orphaned components
5. Architectural improvements and refactoring opportunities
Format your response as markdown sections:
EOF
fi
START_TIME=$(date +%s)
echo "🤖 Running LM Studio analysis..."
if [[ $DEEP_MODE -eq 1 ]]; then
  echo "Using deep architectural analysis mode (timeout: 120s)..."
  send_to_lm_studio "$MIXED_FILE" "$DEEP_AUDIT_FILE"
else
  send_to_lm_studio "$MIXED_FILE" "$AUDIT_OUT"
fi
END_TIME=$(date +%s)
DURATION=$((END_TIME-START_TIME))
echo "📑 Splitting findings..."
split_section() {
    local section="$1"
    local file="$2"
    local header="$3"
    awk "/^## $section/{flag=1;next}/^## /{flag=0}flag" "$AUDIT_OUT" | \
        sed '/^\s*$/d' | \
        awk -v h="$header" 'BEGIN{print h "\n"} {print}' > "$file"
}
declare -A HEADERS
HEADERS["TODO Issues"]="---
status: pending
priority: high
assignee: claude_code
---"
HEADERS["Dead Code"]="---
status: pending
priority: medium
assignee: claude_code
---"
HEADERS["Mocks and Stubs"]="---
status: pending
priority: medium
assignee: claude_code
---"
HEADERS["Duplicate Code"]="---
status: pending
priority: low
assignee: claude_code
---"
HEADERS["Unwired Components"]="---
status: pending
priority: medium
assignee: claude_code
---"
for section in "TODO Issues" "Dead Code" "Mocks and Stubs" "Duplicate Code" "Unwired Components"; do
    outfile="$TASKS_DIR/${section,,}.md"
    outfile="${outfile// /_}"
    split_section "$section" "$outfile" "${HEADERS[$section]}"
done
echo "📝 Regenerating prompts..."
gen_claude_prompt() {
    local section="$1"
    local src="$2"
    local out="$3"
    local intro="$4"
    {
        echo "$intro"
        echo -e "\n## Audit Section: $section\n"
        awk 'f;/^---/{c++}c==2{f=1}' "$src" | sed '/^\s*$/d'
    } > "$out"
}
declare -A PROMPTS
PROMPTS["TODO Issues"]="You are Claude Code. Based on the findings below, perform the following:
- Fix the listed issues in-place
- Leave comments where changes are made
- Do not delete anything unless clearly marked dead/unreachable"
PROMPTS["Dead Code"]="You are Claude Code. Review the following dead code candidates and recommend safe removals or refactors. Only delete if clearly unreachable."
PROMPTS["Mocks and Stubs"]="You are Claude Code. Review the following mocks and stubs. Replace with real implementations where possible."
PROMPTS["Duplicate Code"]="You are Claude Code. Review the following duplicate code findings. Refactor to remove redundancy."
PROMPTS["Unwired Components"]="You are Claude Code. Review the following unwired components. Integrate or remove as appropriate."
for section in "TODO Issues" "Dead Code" "Mocks and Stubs" "Duplicate Code" "Unwired Components"; do
    infile="$TASKS_DIR/${section,,}.md"
    infile="${infile// /_}"
    outfile="$PROMPTS_DIR/CLAUDE_${section,,}.txt"
    outfile="${outfile// /_}"
    gen_claude_prompt "$section" "$infile" "$outfile" "${PROMPTS[$section]}"
done
mkdir -p "$(dirname "$PHASE4_LOG")" || {
    echo "❌ Failed to create log directory: $(dirname "$PHASE4_LOG")"
    exit 1
}
# Generate log with proper escaping
cat > "$PHASE4_LOG" << 'EOF'
- Time: $(date)
- Duration: ${DURATION}s
- Model: $LLM_MODEL
- Temperature: $LLM_TEMP
- Est. Input Tokens: ~$(wc -c < "$MIXED_FILE") chars/4
- Working Directory: $TMP_DIR
- $AUDIT_OUT (Full LM Studio analysis)
- $TASKS_DIR/todo_issues.md
- $TASKS_DIR/dead_code.md
- $TASKS_DIR/mocks_and_stubs.md
- $TASKS_DIR/duplicate_code.md
- $TASKS_DIR/unwired_components.md
- $PROMPTS_DIR/CLAUDE_todo_issues.txt
- $PROMPTS_DIR/CLAUDE_dead_code.txt
- $PROMPTS_DIR/CLAUDE_mocks_and_stubs.txt
- $PROMPTS_DIR/CLAUDE_duplicate_code.txt
- $PROMPTS_DIR/CLAUDE_unwired_components.txt
- $PHASE4_LOG (This summary)
\`\`\`sh
export LLM_MODEL="meta-llama-3.1-8b-instruct"
export LLM_TEMP=0.2
./run_llm_audit.sh
./run_llm_audit.sh --show-payload
./run_llm_audit.sh --dry
bash audits/show_task_status.sh
\`\`\`
1. Generated smart repo summary with repomix
   - Limited scan to high-signal patterns
   - Added file structure overview
   - Used intelligent output limits (50 lines per section)
2. Processed through LM Studio
   - Standard mode: Issues and tasks analysis
   - Deep mode: Full architectural assessment (120s timeout)
3. Split findings into task files
4. Generated task prompts
5. Created detailed summary reports
1. Review the audit in $AUDIT_OUT
2. Use \`send_to_claude.sh\` with generated prompts
3. Track progress in task files
EOF
if [[ -f "$AUDIT_OUT" ]]; then
    mkdir -p "$(dirname "$CLAUDE_FILE")" || {
        echo "❌ Failed to create directory for Claude tasks: $(dirname "$CLAUDE_FILE")"
        exit 1
    }
    # Generate with proper escaping and error checking
    {
        cat << EOF
---
project: ${PROJECT_NAME//\'/\'\\\'\'}
type: code-audit
status: pending
---
# Code Audit Tasks
EOF
        # Extract and transform sections, checking for errors
        if ! awk '/^## /{p=1}p' "$AUDIT_OUT" | sed 's/^##/###/'; then
            echo "❌ Failed to process audit sections"
            exit 1
        fi
    } > "$CLAUDE_FILE"
    if [[ -s "$CLAUDE_FILE" ]]; then
        echo "📋 Claude task list generated: $CLAUDE_FILE"
    else
        echo "⚠️ Warning: Generated Claude task list is empty"
    fi
fi
if [[ $DRY_RUN -eq 1 ]]; then
    echo "✨ Summary generated at: $MIXED_FILE"
    exit 0
fi
echo "✅ Audit complete for $PROJECT_NAME"
echo "📊 Summary: $PHASE4_LOG"
echo "📝 Claude tasks: $CLAUDE_FILE"
```

## File: send_to_claude.sh
```bash
PROJECT_NAME="GMAILspambot"
AUDIT_ROOT="/home/greenantix/AI/audits/$PROJECT_NAME"
PROMPTS_DIR="$AUDIT_ROOT/prompts"
OUTPUT_DIR="$AUDIT_ROOT/responses"
mkdir -p "$OUTPUT_DIR"
echo "🚀 Dispatching Claude tasks via CLI for $PROJECT_NAME..."
find "$PROMPTS_DIR" -type f -name 'CLAUDE_*.txt' | sort | while read -r PROMPT_FILE; do
    TASK_NAME=$(basename "$PROMPT_FILE" .txt | sed 's/^CLAUDE_//')
    OUTPUT_FILE="$OUTPUT_DIR/$TASK_NAME.response.md"
    echo "🧠 Task: $TASK_NAME"
    claude --dangerously-skip-permissions --continue <<EOF > "$OUTPUT_FILE"
You are Claude Code. Analyze the following task file and provide a complete implementation plan or code as needed.
=== TASK BEGIN ===
$(cat "$PROMPT_FILE")
=== TASK END ===
EOF
    echo "✅ Saved: $OUTPUT_FILE"
done
echo "📬 All tasks complete. Responses saved in: $OUTPUT_DIR"
```

## File: setup_env.sh
```bash
export PATH="$HOME/.local/bin:$PATH"
```

## File: start_llmdiver.sh
```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"
DAEMON_SCRIPT="llmdiver_daemon.py"
PID_FILE="llmdiver.pid"
LOG_FILE="llmdiver_daemon.log"
start_daemon() {
    if [ -f "$PID_FILE" ]; then
        PID=$(cat "$PID_FILE")
        if ps -p "$PID" > /dev/null 2>&1; then
            echo "LLMdiver daemon is already running (PID: $PID)"
            return 1
        else
            echo "Removing stale PID file"
            rm -f "$PID_FILE"
        fi
    fi
    echo "Starting LLMdiver daemon..."
    if ! command -v repomix &> /dev/null; then
        echo "❌ Error: repomix not found. Install with: npm install -g repomix"
        exit 1
    fi
    if ! python3 -c "import git, watchdog" 2>/dev/null; then
        echo "❌ Error: Missing Python dependencies. Install with: pip install gitpython watchdog"
        exit 1
    fi
    if ! curl -s http://127.0.0.1:1234/v1/models >/dev/null 2>&1; then
        echo "⚠️  Warning: LM Studio not accessible at http://127.0.0.1:1234"
        echo "   Make sure LM Studio is running with API enabled"
    fi
    mkdir -p config
    nohup python3 "$DAEMON_SCRIPT" > "$LOG_FILE" 2>&1 &
    PID=$!
    echo $PID > "$PID_FILE"
    sleep 2
    if ps -p "$PID" > /dev/null 2>&1; then
        echo "✅ LLMdiver daemon started successfully (PID: $PID)"
        echo "📋 Log file: $LOG_FILE"
        echo "🔍 Monitor with: tail -f $LOG_FILE"
        return 0
    else
        echo "❌ Failed to start daemon"
        rm -f "$PID_FILE"
        return 1
    fi
}
stop_daemon() {
    if [ ! -f "$PID_FILE" ]; then
        echo "LLMdiver daemon is not running"
        return 1
    fi
    PID=$(cat "$PID_FILE")
    echo "Stopping LLMdiver daemon (PID: $PID)..."
    if ps -p "$PID" > /dev/null 2>&1; then
        kill "$PID"
        sleep 2
        if ps -p "$PID" > /dev/null 2>&1; then
            echo "Force killing daemon..."
            kill -9 "$PID"
        fi
        rm -f "$PID_FILE"
        echo "✅ LLMdiver daemon stopped"
    else
        echo "Daemon was not running, removing PID file"
        rm -f "$PID_FILE"
    fi
}
status_daemon() {
    if [ -f "$PID_FILE" ]; then
        PID=$(cat "$PID_FILE")
        if ps -p "$PID" > /dev/null 2>&1; then
            echo "✅ LLMdiver daemon is running (PID: $PID)"
            if [ -f "$LOG_FILE" ]; then
                echo ""
                echo "📋 Recent log entries:"
                tail -n 5 "$LOG_FILE"
            fi
            if [ -d ".llmdiver" ]; then
                echo ""
                echo "📁 Recent analyses:"
                ls -lt .llmdiver/*.md 2>/dev/null | head -n 3
            fi
            return 0
        else
            echo "❌ LLMdiver daemon is not running (stale PID file)"
            return 1
        fi
    else
        echo "❌ LLMdiver daemon is not running"
        return 1
    fi
}
restart_daemon() {
    stop_daemon
    sleep 1
    start_daemon
}
show_logs() {
    if [ -f "$LOG_FILE" ]; then
        tail -f "$LOG_FILE"
    else
        echo "No log file found"
    fi
}
case "$1" in
    start)
        start_daemon
        ;;
    stop)
        stop_daemon
        ;;
    restart)
        restart_daemon
        ;;
    status)
        status_daemon
        ;;
    logs)
        show_logs
        ;;
    *)
        echo "Usage: $0 {start|stop|restart|status|logs}"
        echo ""
        echo "Commands:"
        echo "  start   - Start the LLMdiver daemon"
        echo "  stop    - Stop the LLMdiver daemon"
        echo "  restart - Restart the LLMdiver daemon"
        echo "  status  - Show daemon status and recent activity"
        echo "  logs    - Show live daemon logs"
        echo ""
        echo "Examples:"
        echo "  ./start_llmdiver.sh start"
        echo "  ./start_llmdiver.sh status"
        echo "  ./start_llmdiver.sh logs"
        exit 1
        ;;
esac
```

## File: start_with_audit.sh
```bash
TARGET_REPO="../GMAILspambot"
AUDIT_SCRIPT="./run_llm_audit.sh"
CLAUDE_CMD="claude --dangerously-skip-permissions --continue"
AUDIT_FILE="./audits/$(basename "$TARGET_REPO")/claude.md"
echo "🔍 Running preflight audit on $TARGET_REPO..."
$AUDIT_SCRIPT "$TARGET_REPO" --fast
echo "🚀 Starting Claude Code with audit context..."
$CLAUDE_CMD <<EOF
Please load the following audit report into memory and continuously reference it while working on this project.
The audit is in Markdown format and includes TODOs, mocks, dead code, and unwired modules. Periodically recheck the file to stay up-to-date.
--- START OF AUDIT ---
$(cat "$AUDIT_FILE")
--- END OF AUDIT ---
EOF
```

## File: start-llmdiver.sh
```bash
set -e
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
LOG_DIR="$SCRIPT_DIR/logs"
METRICS_DIR="$SCRIPT_DIR/metrics"
PID_FILE="/tmp/llmdiver-daemon.pid"
LOG_FILE="$LOG_DIR/llmdiver.log"
METRICS_FILE="$METRICS_DIR/metrics.json"
mkdir -p "$LOG_DIR" "$METRICS_DIR"
if [[ -f "$LOG_FILE" && $(stat -f%z "$LOG_FILE" 2>/dev/null || stat -c%s "$LOG_FILE") -gt 104857600 ]]; then
    mv "$LOG_FILE" "$LOG_FILE.$(date +%Y%m%d-%H%M%S)"
    gzip "$LOG_FILE".* &
fi
check_health() {
    if ! curl -s http://localhost:8080/status >/dev/null; then
        echo "❌ Daemon is not responding"
        return 1
    fi
    echo "✅ Daemon is healthy"
    return 0
}
start_daemon() {
    echo "🚀 Starting LLMdiver daemon..."
    if [[ -f "$PID_FILE" ]]; then
        if kill -0 $(cat "$PID_FILE") 2>/dev/null; then
            echo "⚠️ Daemon is already running"
            return 1
        fi
        rm "$PID_FILE"
    fi
    python3 "$SCRIPT_DIR/llmdiver-daemon.py" > "$LOG_FILE" 2>&1 &
    echo $! > "$PID_FILE"
    sleep 2
    if ! check_health; then
        echo "❌ Failed to start daemon"
        return 1
    fi
    echo "✅ Daemon started successfully"
    return 0
}
stop_daemon() {
    echo "🛑 Stopping LLMdiver daemon..."
    if [[ ! -f "$PID_FILE" ]]; then
        echo "⚠️ No PID file found"
        return 0
    fi
    pid=$(cat "$PID_FILE")
    if ! kill -0 "$pid" 2>/dev/null; then
        echo "⚠️ Process not found"
        rm "$PID_FILE"
        return 0
    fi
    kill "$pid"
    rm "$PID_FILE"
    echo "✅ Daemon stopped"
    return 0
}
show_status() {
    if [[ ! -f "$PID_FILE" ]]; then
        echo "❌ Daemon is not running"
        return 1
    fi
    pid=$(cat "$PID_FILE")
    if ! kill -0 "$pid" 2>/dev/null; then
        echo "❌ Daemon process not found (PID: $pid)"
        rm "$PID_FILE"
        return 1
    fi
    if check_health; then
        if [[ -f "$METRICS_FILE" ]]; then
            echo -e "\n📊 Performance Metrics:"
            jq . "$METRICS_FILE"
        fi
        return 0
    fi
    return 1
}
case "${1:-status}" in
    start)
        start_daemon
        ;;
    stop)
        stop_daemon
        ;;
    restart)
        stop_daemon
        sleep 1
        start_daemon
        ;;
    status)
        show_status
        ;;
    health)
        check_health
        ;;
    *)
        echo "Usage: $0 {start|stop|restart|status|health}"
        exit 1
        ;;
esac
```

## File: test_llmdiver.sh
```bash
echo "=== LLMdiver Migration Test ==="
echo
echo "1. Testing configuration..."
cd /home/greenantix/AI/LLMdiver
python3 -c "
from llmdiver_daemon import LLMdiverConfig
config = LLMdiverConfig('config/llmdiver.json')
print(f'✅ Configuration loaded: {len(config.config[\"repositories\"])} repositories')
"
echo
echo "2. Testing multi-project discovery..."
python3 -c "
from llmdiver_daemon import MultiProjectManager
config = {'multi_project': {'enabled': True, 'projects_root': '/home/greenantix/AI', 'auto_discover': True, 'discovery_patterns': ['.git'], 'exclude_paths': ['node_modules', '__pycache__']}}
manager = MultiProjectManager(config)
projects = manager.discover_projects()
print(f'✅ Discovered {len(projects)} projects')
"
echo
echo "3. Testing manifest analysis..."
python3 -c "
from llmdiver_daemon import ManifestAnalyzer
config = {'manifest_analysis': {'enabled': True, 'manifest_files': ['package.json', 'requirements.txt']}}
analyzer = ManifestAnalyzer(config)
manifests = analyzer.find_manifests('/home/greenantix/AI/GMAILspambot')
print(f'✅ Found {len(manifests)} manifests')
"
echo
echo "4. Testing daemon initialization..."
python3 -c "
from llmdiver_daemon import LLMdiverDaemon
import logging
logging.getLogger().setLevel(logging.ERROR)  # Suppress info logs
daemon = LLMdiverDaemon()
print(f'✅ Daemon initialized with {len(daemon.config.config[\"repositories\"])} repositories')
"
echo
echo "5. Checking dependencies..."
if command -v repomix &> /dev/null; then
    echo "✅ repomix available"
else
    echo "❌ repomix not found"
fi
if python3 -c "import git, watchdog, requests" 2>/dev/null; then
    echo "✅ Python dependencies available"
else
    echo "❌ Missing Python dependencies"
fi
echo
echo "6. Testing LM Studio connectivity..."
if curl -s http://127.0.0.1:1234/v1/models >/dev/null 2>&1; then
    echo "✅ LM Studio accessible"
else
    echo "⚠️  LM Studio not accessible (this is optional)"
fi
echo
echo "=== Migration Test Complete ==="
echo "The LLMdiver daemon has been successfully migrated and configured!"
echo
echo "To start the daemon:"
echo "  ./start_llmdiver.sh start"
echo
echo "To check status:"
echo "  ./start_llmdiver.sh status"
echo
echo "To view logs:"
echo "  ./start_llmdiver.sh logs"
```

## File: watch_and_audit.sh
```bash
TARGET_REPO="../GMAILspambot"
AUDIT_SCRIPT="./run_llm_audit.sh"
find "$TARGET_REPO" -type f | entr -c "$AUDIT_SCRIPT" "$TARGET_REPO" --fast
```
